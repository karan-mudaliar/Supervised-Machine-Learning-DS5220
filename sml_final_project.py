# -*- coding: utf-8 -*-
"""SML final project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hsgFgqlPerOl_isgHpaWCEm97pyVaqkW
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow
# %pip install matplotlib
# %pip install keras
# %pip install pydot
# %pip install graphviz

import tensorflow as tf
from tensorflow.keras import layers, models, applications
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score

# Define the requested CNN architecture
def cnn():
    model = models.Sequential()
    model.add(layers.Conv2D(32, kernel_size=3, padding='same', activation='swish', input_shape=(32, 32, 3)))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(64, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Dropout(0.2))

    model.add(layers.Conv2D(128, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(128, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(256, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(256, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Dropout(0.4))

    model.add(layers.Conv2D(512, kernel_size=3, padding='same', activation='swish'))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Dropout(0.5))

    model.add(layers.Flatten())
    model.add(layers.Dense(1024, activation='swish'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(512, activation='swish'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(10, activation='softmax'))

    return model


# Load and preprocess CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

# Create and compile the model
model = cnn()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
num_epochs = 50
history = model.fit(x_train, y_train, batch_size=256, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)

# Plot the training and test losses
plt.figure()
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot the training and test accuracies
plt.figure()
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

CNN = model
CNN.summary()
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Convert y_test to the same format as y_pred
y_true = np.argmax(y_test, axis=-1)

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Calculate precision and recall for each class
precision = precision_score(y_true, y_pred, average=None)
recall = recall_score(y_true, y_pred, average=None)

# Calculate average precision and recall
average_precision = np.mean(precision)
average_recall = np.mean(recall)
accuracy = accuracy_score(y_true, y_pred)

print("Average Precision:", average_precision*100)
print("Average Recall:", average_recall*100)
print("Accuracy:", accuracy*100)

tf.keras.utils.plot_model(CNN, to_file="cnn_model.png", show_shapes=True)

# Define a simple feedforward neural network
def nn():
    model = models.Sequential()
    model.add(layers.Flatten(input_shape=(32, 32, 3)))

    model.add(layers.Dense(2048))
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('swish'))

    model.add(layers.Dense(1024))
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('swish'))

    model.add(layers.Dense(512))
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('swish'))

    model.add(layers.Dense(10, activation='softmax'))

    return model


# Create and compile the model
model = nn()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
num_epochs = 15
history = model.fit(x_train, y_train, batch_size=256, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)

# Plot the training and test losses
plt.figure()
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot the training and test accuracies
plt.figure()
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

DNN = model
DNN.summary()
y_pred = np.argmax(model.predict(x_test), axis=-1)

# Convert y_test to the same format as y_pred
y_true = np.argmax(y_test, axis=-1)

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Calculate precision and recall for each class
precision = precision_score(y_true, y_pred, average=None)
recall = recall_score(y_true, y_pred, average=None)

# Calculate average precision and recall
average_precision = np.mean(precision)
average_recall = np.mean(recall)
accuracy = accuracy_score(y_true, y_pred)

print("Average Precision:", average_precision*100)
print("Average Recall:", average_recall*100)
print("Accuracy:", accuracy*100)

